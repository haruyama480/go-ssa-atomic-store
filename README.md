# go-ssa-atomic-store

Zenn記事へのリンク(TBD)


# タイトル: ARMアーキテクチャがメモリアクセスを省略することで意図したベンチマークになっていなかった話

## 概要
とある書籍のサンプルコードでベンチマークを測ったところ、期待する18倍の結果が出力されました。バイナリを見るとCPU命令は1つしか違いませんでした。不思議に思って調べてみると、ARMアーキテクチャが連続したメモリへの書き込みを1つにマージするらしく、それが原因で正しくベンチマークが測れていませんでした。

パフォーマンスの解釈にアーキテクチャのメモリアクセスの理解が必要だった事例として面白かった記事にしてみました。Go言語で説明しますが、言語に依存しない話題だと思います。

## 得られた教訓
- Goにおけるバイナリの確認方法
- バイナリを見ても説明できない性能差は、アーキテクチャの理解によって説明できることがある
- マイクロベンチマークの計測は何を計測しているのかよく考える必要がある

## 不思議なベンチマーク結果

Go言語 100Tips「No.89: 不正確なベンチマークを書く」(p.313; [web版](https://100go.co/89-benchmarks/#making-wrong-assumptions-about-micro-benchmarks))に、以下のサンプルコードがあります。
この atomic.StoreInt32関数は、アトミックなストアを保証するためにメモリアクセスを行います。
```go
func BenchmarkAtomicStoreInt32(b *testing.B) {
	var v int32
	for i := 0; i < b.N; i++ {
		atomic.StoreInt32(&v, 1)
	}
}
```

Goでは、`go test -bench .`により簡単にベンチマークを取ることができます。(`ns/op`は 1op(今回の例ではatomic~の1行)あたりの実行時間です。)
```
% go test -bench .
goos: darwin
goarch: arm64
pkg: github.com/haruyama480/go-ssa-atomic-store
BenchmarkAtomicStoreInt32-10            1000000000               0.3120 ns/op
```

ベンチマークの結果、自分の環境では`0.3165 ns/op` という結果になりました。
しかし、本では`5.682 ns/op`と記載されており、18倍もの速度差がでてしまいました。

何がこの速度差を生んでいるのでしょうか？
- プロセッサに違いがあるものの(本の環境はIntel(AMD64)で自分の環境はApple Silicon(ARM64))、それで10倍以上速くなることはあるのでしょうか？
- もしかして本の執筆後にコンパイラが賢くなり、最適化によって命令が省略されるようになったのでしょうか？

結論から言うと、コンパイラによる最適化は起きておらず純粋にARMアーキテクチャがメモリアクセスを高速化していたため、想定するベンチマークが取れていませんでした。

## 調査
バイナリを見ることでコンパイラの最適化の有無を調査しました。
サンプルコードは [github](https://github.com/haruyama480/go-ssa-atomic-store)に置いています。

### ベンチマークを増やす

とりあえずベンチマークを増やして実験してみました。本と同等の性能になるケースを見つければ、高速化の要因を探っていけるはずです。

```go
func BenchmarkAtomicStoreInt32Add(b *testing.B) {
	var v int32
	for i := 0; i < b.N; i++ {
		atomic.StoreInt32(&v, int32(i)+1)
	}
}

func BenchmarkAtomicStoreInt32Inc(b *testing.B) {
	var v int32
	for i := 0; i < b.N; i++ {
		atomic.StoreInt32(&v, v+1)
	}
}

func BenchmarkEmpty(b *testing.B) {
	for i := 0; i < b.N; i++ {}
}
```

それぞれのテストを、Addテスト、Incテスト、Emptyテストと呼ぶことにします。
Addテストは過去の値を使いませんが、足し算を行ってvに代入します。
Incテストは過去のvの値を使って、足し算を行います。
Emptyテストは何もしませんが、他の結果がどれだけ速いかの指標になります。

ベンチマークの結果は以下でした。
```shell
BenchmarkAtomicStoreInt32-10            1000000000               0.3119 ns/op
BenchmarkAtomicStoreInt32Add-10         1000000000               0.3139 ns/op
BenchmarkAtomicStoreInt32Inc-10         202822557                5.910 ns/op
BenchmarkEmpty-10                       1000000000               0.3110 ns/op
```

過去のvの結果を使わないAddテストは、Emptyテストの結果と同等になりました。
Incテストと本は似たような結果になりました。

Emptyテストの結果と同等の結果を見ると、最適化によって高速化されているように見えます。実際に計算処理に該当する命令が削られているのでしょうか？

コンパイラが生成する中間表現であるSSAと、最終的に出力するバイナリを調べていきましょう。

### SSAの差分
goはコードをコンパイルする際にSSA形式に変換します。
各関数に対応するSSAは以下のように出力でき、出力された`ssa.html`をブラウザで開くことで、コードがASTに変換され最適化される過程をGUIで確認することができます。
```shell
GOSSAFUNC=AtomicEmpty go build main.go
```

(GUIの例)
![](https://storage.googleapis.com/zenn-user-upload/50772c803561-20240222.png)

各関数のSSAを出力し、比較してみました。

```json
// Empty
MOVD $0, R0
JMP 6
ADD $1, R0, R0
CMP $100, R0
BLT 5
MOVD $0, R0
RET
END

// Add
MOVD $type:int32(SB), R0
PCDATA $1, $0
CALL runtime.newobject(SB)
MOVD $0, R1
JMP 11
ADD $1, R1, R2  // 差分
STLRW R2, (R0)  //
ADD $1, R1, R1
CMP $100, R1
BLT 8
MOVW (R0), R0
RET
END

// Inc
MOVD $type:int32(SB), R0
PCDATA $1, $0
CALL runtime.newobject(SB)
MOVD $0, R1
JMP 12
MOVW (R0), R2   // 差分
ADD $1, R2, R2  //
STLRW R2, (R0)  //
ADD $1, R1, R1
CMP $100, R1
BLT 8
MOVW (R0), R0
RET
END
```

見ての通り、差分は最大でも3行でした。

意外だったのが、EmptyとAddのSSAが異なっていることです。
AddはEmptyと同等に速かったので、最適化されていれば同じSSAに変換されると思っていました。

### バイナリの差分

関数に対応するSSAを見ても、実際には、インライン展開やリンクタイム最適化が働き、まだ変換される余地があります。

最終的に出力されたバイナリを逆アセンブルすることで、真に何の命令が速度差を生んでいるのか見ていきます。
```shell
go build -o main main.go
otool -tvV main
```

以下が逆アセンブル結果です。for分の中身に該当する部分のみ抜き出しています。

```
_main.main:
...
add	x2, x1, #0x1  // AtomicStoreInt32Addのfor文の中身
stlr    w2, [x0]  //
add x1, x1, #0x1  //
...
ldrsw   x2, [x0]  // AtomicStoreInt32Incのfor文の中身
add x2, x2, #0x1  //
stlr    w2, [x0]  //
add x1, x1, #0x1  //
...
```

どうやら差分は`ldrsw x2, [x0]`という1命令のみのようです。
[LDRSWのドキュメント](https://developer.arm.com/documentation/ddi0602/2023-12/Base-Instructions/LDRSW--register---Load-Register-Signed-Word--register--?lang=en#XtOrXZR__11)を読んでみると、メモリからx0レジスタで指定するアドレスの値を読み取り、x2レジスタに格納する命令のようです。

メモリから読み取るという1命令だけで、19倍の性能差が出てしまっているようです。

### どうしてこんなにも性能差が出るのか？

前提として、armアーキテクチャとそのメモリアクセスの順序を理解する必要がありそうです。

https://developer.arm.com/documentation/102376/0100/Memory-access-ordering (以下、ChatGPTによる訳)
> 私たちのガイド「Armv8-A命令セットアーキテクチャ」では、シンプルシーケンシャル実行（SSE）を紹介しています。SSEは、命令の順序付けに関する概念モデルです。メモリアクセスの順序と命令の順序は、異なるが関連する概念です。これらの違いを理解することが重要です。
> 
> SSEは、プロセッサが命令を実行する順序を示します。要約すると、現代のプロセッサには長く複雑なパイプラインがあります。これらのパイプラインは、パフォーマンスを最大化するために、しばしば命令を並べ替えたり、複数の命令を並行して実行したりすることができます。SSEとは、プロセッサがプログラムコードに記述されている順序で、一度に1つの命令を実行しているかのように振る舞わなければならないことを意味します。これは、ハードウェアによる任意の命令の並べ替えや複数発行が、ソフトウェアには見えないものでなければならないことを意味します。
> 
> メモリの順序付けは、メモリアクセスがメモリシステムにおいて現れる順序に関するものです。ライトバッファーやキャッシュのようなメカニズムのために、命令が順番に実行されたとしても、関連するメモリアクセスが順番に実行されない場合があります。これが、プロセッサが命令のためにSSEモデルに従っているとしても、メモリの順序付けを考慮することが重要な理由です。

ふむふむ
- メモリアクセス順序(memory access ordering) と命令順序(instructions ordering)は異なる概念
- SSEモデルにより見かけ上の命令の実行順序が保証される
- しかし、ライトバッファーやキャッシュメモリのようなメカニズムがあるためメモリアクセスの順序付けは保証されない

さらに読んでいくと、衝撃の事実を知りました。

https://developer.arm.com/documentation/102376/0100/Normal-memory (以下、ChatGPTによる訳)

> コードは、複数回同じ場所にアクセスしたり、連続する複数の場所にアクセスしたりすることができます。効率のため、プロセッサはこれらのアクセスを検出して単一のアクセスにマージすることが許可されています。例えば、ソフトウェアが変数に複数回書き込む場合、プロセッサはメモリシステムに最後の書き込みのみを提示するかもしれません。

つまり、Addテストの場合、同一アドレスへの書き込みが複数連続していたため、それらはアーキテクチャによってマージされ、最後の書き込みのみが実行されるようです。これによって高速に実行されていたのですね。[merge]

ちなみに、Incテストの場合、同じアドレスに書き込みと読み込みを交互に行っていたため、並び替え(reorder)は発生せずプロセッサはメモリアクセスを順序通りに実行してくれているようです。

> 同じ場所へのアクセスは並べ替えることができませんが、マージされることはあります

最終的に、以下のfor分でN回回していたはずのStoreInt32は実際には最後の1回しか実行されない可能性があるようです。
```go
	for i := 0; i < b.N; i++ {
		atomic.StoreInt32(&v, 1)
	}
```

### メモリアクセスのマージの確認

もしメモリアクセスがマージされているのであれば、Nによってベンチマークの結果が変わります。
goは`-benchtime=Nx`オプションによってNの値を変化させることができます。

```
% go test -bench 'StoreInt32$' -benchtime=100x
(略)
BenchmarkAtomicStoreInt32-10                 100                 2.920 ns/op

% go test -bench 'StoreInt32$' -benchtime=1000x
(略)
BenchmarkAtomicStoreInt32-10                1000                 0.8750 ns/op
```

明らかにNの回数に対してベンチマーク結果が変わります。メモリアクセスのマージが行われていると判断して良いでしょう

## 何が問題だったのか
今回、コンパイラもハードウェアも正しい最適化を行っており何も悪いことはしていません。
しかし、測定されていたベンチマークは意図したものではありませんでした。

問題は主に2つあると考えています。

1つは、**イテレーション間に干渉があったこと**です。

ほとんどのベンチマークは、ばらつきを防ぐためにfor文でN回イテレーションを実行し、合計実行時間/イテレーション回数によって平均実行時間(`ns/op`)を算出します。しかし、イテレーションをまたいだ最適化が起きると実際の実行回数が本来のNではなくなり、平均実行時間は過小評価されてしまいます。また、Goはデフォルトで合計実行時間1秒に収まるように Nを自動的に設定するため、スペックの良いプロセッサほどNが大きくなり、改善を過大評価してしまう可能性があります。

イテレーション間でキャッシュを共有するベンチマークにも同様のことが言えるでしょう。

メモリアクセスの省略やキャッシュ込みでベンチマークを取りたいことがあるかもしれません。
その場合でも、上記を理由にN回のイテレーションは干渉させるべきではないでしょう。

```go
	// NG
	c := WithCache{}
	for i := 0; i < b.N; i++ {
		c.Calc()
	}

	// OK
	const M = 1000
	for i := 0; i < b.N; i++ {
		c := WithCache{}
		for j := 0; j < M; j++ {
			c.Calc()
		}
	}
```

もう1つは、**マイクロベンチマークは注意深く実施する必要があること**です。
Go言語100Tipsにも書かれていますが、マクロベンチマークは多くの要因が結果に影響を与え、間違った仮定へ導く可能性があります。今回の例も、一見するとコンパイラの最適化が要因だと考えられました。また、バイナリの命令列だけではなく、アーキテクチャ固有の仕様を理解することが必要でした。ベンチマークを取った後も、それは正しい計測になっているかを様々な角度で検証できるとよいでしょう。

これら以外にも問題があげられると思います。気になる方は、詳解システム・パフォーマンス「12章 ベンチマーキング」が網羅的で面白かったので一読をオススメします。

## まとめ
- AtomicStoreInt32Add と AtomicStoreInt32Inc の速度差は、コンパイラの最適化によるものではない
- 命令が1つ追加されるだけで、バイナリの実行速度は18倍も変わることがある
- その性能差は、アーキテクチャとそのメモリアクセスモデルの理解を前提とする
- ARM64において、同じアドレスへの連続した書き込み or 読み込みはマージされる可能性がある(採用されなかったメモリアクセスは無かったことになるが、その分高速になる)


[merge]: L1キャッシュへのアクセスといえど、数CPUサイクルを消費してしまうので、N×数サイクル省略できることは確かに大きな性能差を生むことに納得できそう
